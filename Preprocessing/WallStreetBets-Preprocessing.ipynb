{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WallStreetBets-Preprocessing.ipynb","provenance":[{"file_id":"108ofFsEzbswK2E1tzkPfr6UU6jPHRTx-","timestamp":1616988199266}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tSmCrU8CYLkf","executionInfo":{"status":"ok","timestamp":1618276907721,"user_tz":240,"elapsed":59140,"user":{"displayName":"Matthew Pan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCWuFCldWPbrwDhMwSHEPBJGlwSJGy8mYOGuOX=s64","userId":"13652678893782715764"}},"outputId":"de956ad1-6586-4882-824b-c073016f6d40"},"source":["!pip install pyspark\n","!pip install praw\n","!pip3 install iexfinance\n","!pip install pickle-mixin\n","!pip install pandas\n","!pip install requests-futures\n","!pip install holidays"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pyspark\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n","\u001b[K     |████████████████████████████████| 212.3MB 71kB/s \n","\u001b[?25hCollecting py4j==0.10.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n","\u001b[K     |████████████████████████████████| 204kB 50.8MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=366d6b49e970194424c9d917f1ae6151eb2ea5e87d96e08a8353b49ecac86a8a\n","  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9 pyspark-3.1.1\n","Collecting praw\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/a8/a2e2d0750ee17c7e3d81e4695a0338ad0b3f231853b8c3fa339ff2d25c7c/praw-7.2.0-py3-none-any.whl (159kB)\n","\u001b[K     |████████████████████████████████| 163kB 6.8MB/s \n","\u001b[?25hCollecting update-checker>=0.18\n","  Downloading https://files.pythonhosted.org/packages/0c/ba/8dd7fa5f0b1c6a8ac62f8f57f7e794160c1f86f31c6d0fb00f582372a3e4/update_checker-0.18.0-py3-none-any.whl\n","Collecting prawcore<3,>=2\n","  Downloading https://files.pythonhosted.org/packages/7d/df/4a9106bea0d26689c4b309da20c926a01440ddaf60c09a5ae22684ebd35f/prawcore-2.0.0-py3-none-any.whl\n","Collecting websocket-client>=0.54.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/33/80e0d4f60e84a1ddd9a03f340be1065a2a363c47ce65c4bd3bae65ce9631/websocket_client-0.58.0-py2.py3-none-any.whl (61kB)\n","\u001b[K     |████████████████████████████████| 61kB 5.7MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from update-checker>=0.18->praw) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from websocket-client>=0.54.0->praw) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.18->praw) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.18->praw) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.18->praw) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.18->praw) (3.0.4)\n","Installing collected packages: update-checker, prawcore, websocket-client, praw\n","Successfully installed praw-7.2.0 prawcore-2.0.0 update-checker-0.18.0 websocket-client-0.58.0\n","Collecting iexfinance\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/a6/653eb3306789f97f761a7889913923e0e814967a342099d4f11c0604eaa1/iexfinance-0.5.0-py3-none-any.whl (54kB)\n","\u001b[K     |████████████████████████████████| 61kB 4.7MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from iexfinance) (1.1.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from iexfinance) (2.23.0)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->iexfinance) (1.19.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->iexfinance) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->iexfinance) (2.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->iexfinance) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->iexfinance) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->iexfinance) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->iexfinance) (3.0.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->iexfinance) (1.15.0)\n","Installing collected packages: iexfinance\n","Successfully installed iexfinance-0.5.0\n","Collecting pickle-mixin\n","  Downloading https://files.pythonhosted.org/packages/02/77/9d5eb2201bbc130e2a5cc41fc949e4ab0da74b619107eac1c511be3af7a7/pickle-mixin-1.0.2.tar.gz\n","Building wheels for collected packages: pickle-mixin\n","  Building wheel for pickle-mixin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pickle-mixin: filename=pickle_mixin-1.0.2-cp37-none-any.whl size=5999 sha256=4d6a33e095f454f1ed163b57b900588a5061a151858385fd8750225801a326b2\n","  Stored in directory: /root/.cache/pip/wheels/cd/05/42/71de70fa36b9cbb7657bb5793a16f8028c1cdc1bdd3b8e1ac3\n","Successfully built pickle-mixin\n","Installing collected packages: pickle-mixin\n","Successfully installed pickle-mixin-1.0.2\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Collecting requests-futures\n","  Downloading https://files.pythonhosted.org/packages/47/c4/fd48d1ac5110a5457c71ac7cc4caa93da10a80b8de71112430e439bdee22/requests-futures-1.0.0.tar.gz\n","Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures) (1.24.3)\n","Building wheels for collected packages: requests-futures\n","  Building wheel for requests-futures (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for requests-futures: filename=requests_futures-1.0.0-cp37-none-any.whl size=7012 sha256=1b69a94df36a21c028a5498028f8ef8a97f987a1012c1b831023a32925efcca5\n","  Stored in directory: /root/.cache/pip/wheels/26/d0/f5/dc4e4a37bbe55c9acf967d2bd899152412c1e49c227f5395ff\n","Successfully built requests-futures\n","Installing collected packages: requests-futures\n","Successfully installed requests-futures-1.0.0\n","Requirement already satisfied: holidays in /usr/local/lib/python3.7/dist-packages (0.10.5.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from holidays) (2.8.1)\n","Requirement already satisfied: convertdate>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from holidays) (2.3.2)\n","Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays) (0.2.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from holidays) (1.15.0)\n","Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays) (2.1.1)\n","Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays) (2018.9)\n","Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays) (0.5.11)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KV_t_JDlZHAg"},"source":["from pyspark.rdd import RDD\n","from pyspark.sql import Row\n","from pyspark.sql import DataFrame\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import lit\n","from pyspark.sql.functions import desc\n","from pyspark.ml.evaluation import RegressionEvaluator\n","from pyspark.ml.recommendation import ALS\n","from pyspark import SparkContext as sc\n","from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","from iexfinance.stocks import Stock\n","from iexfinance.stocks import get_historical_data\n","import os\n","# tools\n","import re\n","import math\n","import json\n","import requests\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import time\n","from datetime import date\n","from datetime import datetime, timedelta\n","import string\n","import holidays\n","\n","# input true for sandbox\n","def sandbox(change):\n","  if change:\n","    # Set IEX Finance API Token for Sandbox test mode\n","    os.environ['IEX_API_VERSION'] = 'iexcloud-sandbox'\n","    os.environ['IEX_TOKEN'] = ''\n","  else:\n","    # Real\n","    os.environ['IEX_API_VERSION'] = 'stable'\n","    os.environ['IEX_TOKEN'] = ''\n","\n","sandbox(True)\n","\n","def init_spark():\n","    spark = SparkSession \\\n","        .builder \\\n","        .appName(\"Python Spark SQL basic example\") \\\n","        .config(\"spark.some.config.option\", \"some-value\") \\\n","        .getOrCreate()\n","    return spark\n","spark = init_spark()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wK4nDaIo9KCf"},"source":["'''\n","Function to find the ticker of the stock talked about in a post.\n","'''\n","\n","# helper function for get_ticker, extracts ticker after dollar signs if exists\n","def check_after_dollarsign(body, start_index):\n","   \"\"\"\n","   Given a starting index and text, this will extract the ticker, return None if it is incorrectly formatted.\n","   \"\"\"\n","   count  = 0\n","   ticker = \"\"\n","\n","   for char in body[start_index:]:\n","      # if it should return\n","      if not char.isalpha():\n","         # if there aren't any letters following the $\n","         if (count == 0):\n","            return None\n","\n","         return ticker.upper()\n","      else:\n","         ticker += char\n","         count += 1\n","\n","   return ticker.upper()\n","\n","# function to retrieve ticker from a body of text\n","def get_ticker(body):\n","   # frequent words that look like tickers but aren't\n","   blacklist_words = [\n","      \"YOLO\", \"TOS\", \"CEO\", \"CFO\", \"CTO\", \"DD\", \"BTFD\", \"WSB\", \"OK\", \"RH\",\n","      \"KYS\", \"FD\", \"TYS\", \"US\", \"USA\", \"IT\", \"ATH\", \"RIP\", \"BMW\", \"GDP\",\n","      \"OTM\", \"ATM\", \"ITM\", \"IMO\", \"LOL\", \"DOJ\", \"BE\", \"PR\", \"PC\", \"ICE\",\n","      \"TYS\", \"ISIS\", \"PRAY\", \"PT\", \"FBI\", \"SEC\", \"GOD\", \"NOT\", \"POS\", \"COD\",\n","      \"AYYMD\", \"FOMO\", \"TL;DR\", \"EDIT\", \"STILL\", \"LGMA\", \"WTF\", \"RAW\", \"PM\",\n","      \"LMAO\", \"LMFAO\", \"ROFL\", \"EZ\", \"RED\", \"BEZOS\", \"TICK\", \"IS\", \"DOW\"\n","      \"AM\", \"PM\", \"LPT\", \"GOAT\", \"FL\", \"CA\", \"IL\", \"PDFUA\", \"MACD\", \"HQ\",\n","      \"OP\", \"DJIA\", \"PS\", \"AH\", \"TL\", \"DR\", \"JAN\", \"FEB\", \"JUL\", \"AUG\",\n","      \"SEP\", \"SEPT\", \"OCT\", \"NOV\", \"DEC\", \"FDA\", \"IV\", \"ER\", \"IPO\", \"RISE\"\n","      \"IPA\", \"URL\", \"MILF\", \"BUT\", \"SSN\", \"FIFA\", \"USD\", \"CPU\", \"AT\",\n","      \"GG\", \"ELON\", \"I\", \"WE\", \"A\"\n","   ]\n","\n","   # FIRST CHECK IF THERE'S A $TICKER WITH DOLLAR SIGN\n","   if '$' in body:\n","      index = body.find('$') + 1\n","      word = check_after_dollarsign(body, index)\n","      \n","      if word and word not in blacklist_words:\n","         try:\n","            # special case for $ROPE\n","            if word != \"ROPE\":\n","               # sends request to IEX API to determine whether the current word is a valid ticker\n","               # if it isn't, it'll return an error and therefore continue on to the next word\n","               price = Stock(word).get_company()\n","               return word\n","         except Exception as e:\n","            pass\n","   \n","   # IF NO TICKER WITH DOLLAR SIGN, CHECK FOR TICKER WITHOUT IT: splits every body into list of words\n","   word_list = re.sub(\"[^\\w]\", \" \",  body).split()\n","   for count, word in enumerate(word_list):\n","      # initial screening of words\n","      if word.isupper() and len(word) >= 1 and (word.upper() not in blacklist_words) and len(word) <= 5 and word.isalpha():\n","         try:\n","            # special case for $ROPE\n","            if word != \"ROPE\":\n","               price = Stock(word).get_company()\n","               return word\n","         except Exception as e: \n","            continue\n","      \n","   # if no ticker was found\n","   return \"None\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pt_uZ0yx9jm1","executionInfo":{"status":"ok","timestamp":1618276914775,"user_tz":240,"elapsed":66124,"user":{"displayName":"Matthew Pan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCWuFCldWPbrwDhMwSHEPBJGlwSJGy8mYOGuOX=s64","userId":"13652678893782715764"}},"outputId":"f108ddaa-73c5-408b-c16f-4c238127af3b"},"source":["'''\n","Test IEXFinance API ticker extraction\n","'''\n","text = \"I'm going to buy some AAPL yeee.\"\n","ticker = get_ticker(text)\n","# Individual stock test\n","#hi = Stock(\"asdlkjf\").get_company()\n","print(\"Getting random ticker: \", ticker)\n","#quote = Stock(\"AAPL\")\n","# get's stock price\n","#one_price = quote.get_quote().latestPrice[ticker]\n","#print(\"one price: \", one_price)\n","now = datetime.now().timestamp()\n","end = datetime.fromtimestamp(1617658992)\n","start = datetime.fromtimestamp(1617658992 - 86400)\n","# gets the closing prices from a week ago till today. use the latest price!\n","price = get_historical_data(\"AAPL\", start, end, close_only=True)\n","print(price.close)\n","# # get last price!\n","print(price.close[-1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Getting random ticker:  AAPL\n","2021-04-05    132\n","Name: close, dtype: object\n","132\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hQ1VC_zARJ62"},"source":["'''\n","- return false if date is holiday or weekend (market close), else return date\n","'''\n","def get_start_date(created):\n","  # 1 day before post date\n","  us_holidays = holidays.UnitedStates(years = 2021)\n","  ticker_date = datetime.fromtimestamp(int(created) - 86400).date()\n","  \n","  # if not holiday or good friday or weekend\n","  if ticker_date in us_holidays or ticker_date == datetime(2021, 4, 2).date():\n","    return False\n","  if ticker_date.weekday() in [5,6]:\n","    return False\n","  \n","  return ticker_date"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8mY1Y3M8ZE3S","executionInfo":{"status":"ok","timestamp":1618276914776,"user_tz":240,"elapsed":66113,"user":{"displayName":"Matthew Pan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCWuFCldWPbrwDhMwSHEPBJGlwSJGy8mYOGuOX=s64","userId":"13652678893782715764"}},"outputId":"17fd0a1b-bdc6-43f1-fda2-4af84abf50e8"},"source":["newyear = 1609609392\n","get_start_date(newyear)\n","\n","ticker_date = datetime.fromtimestamp(int(1617658992)- 86400 - 86400 - 86400).date()\n","print(ticker_date == datetime(2021, 4, 2).date())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"olDQK62m1WE9"},"source":["'''\n","Compute growth % of associated stock in a given post.\n","'''\n","# computes growth % of given DD\n","# (today's price <> price at DD's date) = percentage growth from then to now of the stock\n","def growth1(ticker, created):\n","    if not ticker or ticker == \"None\":\n","        return \"N/A\"\n","    # get today's date and DD's date (ranges from <>1 week in case of weekends/holidays)\n","    try:\n","        # get today's price\n","        price_today = Stock(ticker).get_quote().latestPrice[ticker]\n","\n","        ticker_date_start = get_start_date(created)\n","        ticker_date_end = datetime.fromtimestamp(int(created))\n","\n","        # dates for post creation: loop until get valid date\n","        counter = 0\n","        new_date = created\n","        while not ticker_date_start and counter < 20:\n","          counter += 1\n","          new_date -= 86400\n","          ticker_date_start = get_start_date(new_date)\n","        # get DD date's price\n","        if ticker_date_start:\n","          # sandbox(True)\n","          # test = get_historical_data(ticker, ticker_date_start, ticker_date_end, close_only=True).close[0]\n","          # sandbox(False)\n","          ticker_date_end = ticker_date_start + timedelta(days=0.8)\n","          price_ticker_date = get_historical_data(ticker, ticker_date_start, ticker_date_end, close_only=True).close[0]\n","\n","        # compute percentage growth\n","        percentage = ((price_today / price_ticker_date) - 1) * 100\n","        return \"{:.2f}\".format(percentage) + \"%\"\n","    except Exception as e:\n","        return \"N/A\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Msq6kRNLLnk0"},"source":["'''\n","Compute growth % of associated stock in a given post.\n","'''\n","# computes growth % of given DD\n","# (today's price <> price at DD's date) = percentage growth from then to now of the stock\n","def growth(ticker, created):\n","    if not ticker or ticker == \"None\":\n","        return \"N/A\"\n","    # get today's date and DD's date (ranges from <>1 week in case of weekends/holidays)\n","    try:\n","        # get today's price\n","        price_today = Stock(ticker).get_quote().latestPrice[ticker]\n","        print(\"ok\",price_today)\n","\n","        ticker_date_start = get_start_date(created)\n","        ticker_date_end = datetime.fromtimestamp(int(created))\n","\n","        # dates for post creation: loop until get valid date\n","        counter = 0\n","        new_date = created\n","        while not ticker_date_start and counter < 20:\n","          counter += 1\n","          new_date -= 86400\n","          ticker_date_start = get_start_date(new_date)\n","        # get DD date's price\n","        if ticker_date_start:\n","          # sandbox(True)\n","          # test = get_historical_data(ticker, ticker_date_start, ticker_date_end, close_only=True).close[0]\n","          # sandbox(False)\n","          ticker_date_end = ticker_date_start + timedelta(days=0.8)\n","          test = get_historical_data(ticker, ticker_date_start, ticker_date_end, close_only=True)\n","          print(\"test\", test)\n","          price_ticker_date = test.close[0]\n","\n","        print(ticker_date_start, ticker_date_end)\n","        # compute percentage growth\n","        percentage = ((price_today / price_ticker_date) - 1) * 100\n","        return \"{:.2f}\".format(percentage) + \"%\"\n","    except Exception as e:\n","        print(e)\n","        return \"N/A\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":97},"id":"SQlBbmteP7o7","executionInfo":{"status":"ok","timestamp":1618276915111,"user_tz":240,"elapsed":66432,"user":{"displayName":"Matthew Pan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCWuFCldWPbrwDhMwSHEPBJGlwSJGy8mYOGuOX=s64","userId":"13652678893782715764"}},"outputId":"8da4decc-f747-4f80-d173-b901d6a8d112"},"source":["'''\n","Test growth function\n","'''\n","# 1/11/2021 -> dont work\n","#date = 1610473392\n","date = 1617656836\n","ticker = \"GME\"\n","#ticker_date_start = datetime.fromtimestamp(int(date) - 86400)\n","ticker_date_start = datetime.fromtimestamp(int(date))\n","ticker_date_end = ticker_date_start + timedelta(days=1)\n","print(ticker_date_start, ticker_date_end)\n","\n","#price_today = get_historical_data(ticker, datetime.fromtimestamp(int(datetime.now().timestamp()) - 604800), close_only=True).close[-1]\n","#price_ticker_date = get_historical_data(ticker, ticker_date, ticker_date_end, close_only=True).close[0]\n","#print(growth(ticker, date))\n","#print(growth(ticker, date))\n","#Stock(ticker).get_price().iloc[0,0]\n","get_historical_data(ticker, ticker_date_start, ticker_date_end, close_only=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-04-05 21:07:16 2021-04-06 21:07:16\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>close</th>\n","      <th>volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-04-06</th>\n","      <td>187.1</td>\n","      <td>6515378</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            close   volume\n","2021-04-06  187.1  6515378"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":88},"id":"zgUPYZ8kni0H","executionInfo":{"status":"ok","timestamp":1618276915113,"user_tz":240,"elapsed":66423,"user":{"displayName":"Matthew Pan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCWuFCldWPbrwDhMwSHEPBJGlwSJGy8mYOGuOX=s64","userId":"13652678893782715764"}},"outputId":"8d178063-6b4f-45d7-bf97-8b8d4e21b116"},"source":["#obj2 = get_request('https://api.pushshift.io/reddit/search/submission?subreddit=wallstreetbets&score=>4&selftext:not=\"[removed]\"&is_video=false&size=25&fields=id,created_utc,title,score,upvote_ratio,author,link_flair_text,link_flair_css_class,num_comments,selftext,url')\n","\n","\"\"\"\n","&selftext:not=\"preview.redd.it\"\n","'id': post['id'],\\\n","            'ticker': ticker, \\\n","            'growth': growth(ticker, post['created_utc']),\\\n","            'title': clean_text(post['title']),\\\n","            'score': post['score'],\\\n","            'upvote_ratio': post['upvote_ratio'],\\\n","            'author': post['author'],\\\n","            'created_utc': post['created_utc'],\\\n","            'flair': post['link_flair_text'],\\\n","            'flaircss': post['link_flair_css_class'],\\\n","            'num_comments': post['num_comments'],\\\n","            'text': clean_text(post['selftext']),\\\n","            'url': post['url']\\\n","\"\"\"\n","# for i in obj2[\"data\"]:\n","#   print(i[\"selftext\"])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n&selftext:not=\"preview.redd.it\"\\n\\'id\\': post[\\'id\\'],            \\'ticker\\': ticker,             \\'growth\\': growth(ticker, post[\\'created_utc\\']),            \\'title\\': clean_text(post[\\'title\\']),            \\'score\\': post[\\'score\\'],            \\'upvote_ratio\\': post[\\'upvote_ratio\\'],            \\'author\\': post[\\'author\\'],            \\'created_utc\\': post[\\'created_utc\\'],            \\'flair\\': post[\\'link_flair_text\\'],            \\'flaircss\\': post[\\'link_flair_css_class\\'],            \\'num_comments\\': post[\\'num_comments\\'],            \\'text\\': clean_text(post[\\'selftext\\']),            \\'url\\': post[\\'url\\']'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"zBk3suhmCqFA"},"source":["'''\n","Data cleaning step\n","- Remove all punctuation, numbers, new lines, tabs, consecutive spaces in text.\n","'''\n","def clean_text(text):\n","  # remove punctuation except $\n","  cleaned = text.translate(str.maketrans(' ', ' ', string.punctuation.replace('$','') + '’')).lower()\n","  # remove links (http)\n","  cleaned = re.sub(\"http\\w+\", \" \", cleaned)\n","  # remove digits\n","  cleaned = cleaned.translate({ord(k): None for k in string.digits})\n","  # remove tabs/newlines\n","  cleaned = cleaned.replace(\"\\n\", \" \").replace(\"\\t\", \" \").strip()\n","  # remove double space\n","  cleaned = re.sub(' +', ' ', cleaned)\n","  return cleaned"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"jDq9c0B9Cy0C","executionInfo":{"status":"ok","timestamp":1618276915117,"user_tz":240,"elapsed":66414,"user":{"displayName":"Matthew Pan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCWuFCldWPbrwDhMwSHEPBJGlwSJGy8mYOGuOX=s64","userId":"13652678893782715764"}},"outputId":"9ea9d7c5-7922-4b6c-efa3-324b907a1022"},"source":["'''\n","Testing clean_text()\n","'''\n","dirty = \" Hi I'm Pan. We a213re http://kek.com g5.3oin2g 5.4 to 3 havhttp://kek.come a VERY\\n  [GOOD GRADE] in \\tthis class: \\nnot even  # kidding, @our project is 2 good... Soyeah!!! If you ask me 'how?' i'll tell u we got 100%.\"\n","print(dirty)\n","print()\n","clean_text(dirty)"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" Hi I'm Pan. We a213re http://kek.com g5.3oin2g 5.4 to 3 havhttp://kek.come a VERY\n","  [GOOD GRADE] in \tthis class: \n","not even  # kidding, @our project is 2 good... Soyeah!!! If you ask me 'how?' i'll tell u we got 100%.\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'hi im pan we are going to hav a very good grade in this class not even kidding our project is good soyeah if you ask me how ill tell u we got'"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"k554ETe-Iwf5"},"source":["'''\n","Data Filtering: validate post before adding.\n","'''\n","\n","def validate_post(post):\n","  return (post['link_flair_text']\n","    and post['upvote_ratio'] > 0.5\n","    and post['link_flair_css_class']\n","    and post['selftext']\n","    and not post['selftext'].isspace()\n","    and post['selftext'] != \"removed\"\n","    and post['selftext'] != \"[deleted]\"\n","    and post['score'] >= 5)\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SR3LG9j9PLog","executionInfo":{"status":"ok","timestamp":1618276915244,"user_tz":240,"elapsed":66528,"user":{"displayName":"Matthew Pan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCWuFCldWPbrwDhMwSHEPBJGlwSJGy8mYOGuOX=s64","userId":"13652678893782715764"}},"outputId":"64a65e9e-f972-454d-eca9-30aa4a424ed3"},"source":["# testing stuff\n","def val():\n","  return (('DD' == 'DD' or 'D' == 'D')\n","    and 6 >= 5\n","    and 2 > 5)\n","\n","val()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"FQkcQb6TnlR_"},"source":["\"\"\"\n","Gets the all the posts from a given subreddit in the specific time range.\n","- subreddit: name of subreddit\n","- begin: timestamp (in unix) of start date\n","- end: timestamp (in unix) of end date\n","- returns: list of all the posts in the time interval as objects. {id=\"..\", title=\"...\", etc...}\n","\"\"\"\n","def get_posts(subreddit, begin, end):\n","  # Max size of each Pushshift API request is 100 posts.\n","  SIZE = 100\n","  #'https://api.pushshift.io/reddit/search/submission?subreddit=wallstreetbets&score=>5&size=25&selftext:not=\"preview.redd.it\"&fields=id,created_utc,title,score,upvote_ratio,author,link_flair_text,link_flair_css_class,num_comments,selftext,url'\n","  PUSHSHIFT_URI = r'https://api.pushshift.io/reddit/search/submission?subreddit={}&after={}&before={}&size={}&socre=>4&selftext:not=\"[removed]\"&is_video=false&fields=total_awards_received,id,created_utc,title,score,upvote_ratio,author,link_flair_text,link_flair_css_class,num_comments,selftext,url'\n","  nb_requests_made = 1\n","\n","  # filter the posts data\n","  def filter_posts(uri, begin, end):\n","    full_posts = get_request(uri.format(subreddit, begin, end, SIZE))\n","    #if full_posts is None:\n","      #raise ValueError(\"Response is empty or none.\")\n","\n","    posts = []\n","    if full_posts!=None:\n","      for post in full_posts['data']:\n","        try:\n","          if validate_post(post):\n","            ticker =  get_ticker(post['title'])\n","            posts.append({\\\n","              'id': post['id'],\\\n","              'ticker': ticker, \\\n","              'growth': growth(ticker, post['created_utc']),\\\n","              'title': clean_text(post['title']),\\\n","              'score': post['score'],\\\n","              'upvote_ratio': post['upvote_ratio'],\\\n","              'author': post['author'],\\\n","              'created_utc': post['created_utc'],\\\n","              'flair': post['link_flair_text'],\\\n","              'flaircss': post['link_flair_css_class'],\\\n","              'num_comments': post['num_comments'],\\\n","              'text': clean_text(post['selftext']),\\\n","              'url': post['url']\\\n","            })\n","        except:\n","          pass\n","      # get timestamp of last post\n","      #print(full_posts['data'][0][\"score\"])\n","      last_timestamp = full_posts['data'][-1]['created_utc']\n","      posts_amount = len(full_posts['data'])\n","          \n","      #return list(filtered)\n","      return [posts, last_timestamp, posts_amount]\n","    else:\n","      return None \n","\n","  posts_etc = filter_posts(PUSHSHIFT_URI, begin, end)\n","  posts = posts_etc[0]\n","  last_timestamp = posts_etc[1]\n","  posts_amount = posts_etc[2]\n","  # If reached limit of 100 posts retrieved, make request again until 'end' time.\n","  while posts_amount == SIZE:\n","    \n","    # Timestamp of the last post we previously retrieved\n","    new_begin = last_timestamp - 10\n","    more_posts_etc = filter_posts(PUSHSHIFT_URI, new_begin, end)\n","    if more_posts_etc==None:\n","      break\n","    last_timestamp = more_posts_etc[1]\n","    posts_amount = more_posts_etc[2]\n","    posts.extend(more_posts_etc[0])\n","    nb_requests_made += 1\n","    print(new_begin,end)\n","    \n","  print(\"Number of requests made: \", nb_requests_made)\n","  return posts"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pv07kukZgPq5","executionInfo":{"status":"ok","timestamp":1618276915245,"user_tz":240,"elapsed":66517,"user":{"displayName":"Matthew Pan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCWuFCldWPbrwDhMwSHEPBJGlwSJGy8mYOGuOX=s64","userId":"13652678893782715764"}},"outputId":"37ae820d-82f8-437b-fc6b-edabbfc0ae54"},"source":["datetime.fromtimestamp(1612264874) - timedelta(days=8)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["datetime.datetime(2021, 1, 25, 11, 21, 14)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":722},"id":"TbNt-2o0O-DC","executionInfo":{"status":"error","timestamp":1618368000128,"user_tz":240,"elapsed":29177,"user":{"displayName":"Matthew Pan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCWuFCldWPbrwDhMwSHEPBJGlwSJGy8mYOGuOX=s64","userId":"13652678893782715764"}},"outputId":"ebe8a5f6-e9c5-4f18-a0aa-1b34e0d71e8d"},"source":["import time\n","for i in range(30):\n","  print(\"[Error] Request failed, credit limit exceeded.\")\n","  time.sleep(1)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n","[Error] Request failed, credit limit exceeded.\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-79c6a284da7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[Error] Request failed, credit limit exceeded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":371},"id":"HPfvW-hwvTFh","executionInfo":{"status":"error","timestamp":1618276915735,"user_tz":240,"elapsed":66997,"user":{"displayName":"Matthew Pan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCWuFCldWPbrwDhMwSHEPBJGlwSJGy8mYOGuOX=s64","userId":"13652678893782715764"}},"outputId":"3403f51f-d1c6-49a0-8c3c-f3402e53aba0"},"source":["\"\"\"\n","Retrieve posts\n","- nb_days_from_today: number of days from 4 days ago you want to retrieve\n","- return: lists of all posts in time interval\n","\"\"\"\n","get_attempts = 0\n","def retrieve(nb_days_from_today):\n","  global get_attempts\n","  end = math.ceil(datetime.utcnow().timestamp() - 345600)\n","  if nb_days_from_today < 3650:\n","    begin = math.ceil((datetime.fromtimestamp(end) - timedelta(days=nb_days_from_today)).timestamp())\n","  else:\n","    begin = nb_days_from_today\n","  print(\"Timestamps: \", begin, end)\n","  posts = get_posts('wallstreetbets', begin, end)\n","\n","  unique_posts = np.unique([post['id'] for post in posts])\n","  print(\"Size: \", len(posts))\n","  print(\"Size of uniques: \", len(unique_posts))\n","  print(\"Example posts: \", posts[:5])\n","  print(\"Total requests: \" + str(get_attempts))\n","  return posts\n","\n","# all posts!\n","#70 days\n","posts = retrieve(1612264874)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Timestamps:  1612264874 1617931315\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-611d718566c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# all posts!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#70 days\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mposts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1612264874\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-17-611d718566c6>\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(nb_days_from_today)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mbegin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_days_from_today\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Timestamps: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mposts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_posts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wallstreetbets'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0munique_posts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mposts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-391011fa1050>\u001b[0m in \u001b[0;36mget_posts\u001b[0;34m(subreddit, begin, end)\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0mposts_etc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_posts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPUSHSHIFT_URI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m   \u001b[0mposts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposts_etc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0mlast_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposts_etc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-391011fa1050>\u001b[0m in \u001b[0;36mfilter_posts\u001b[0;34m(uri, begin, end)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m# filter the posts data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfilter_posts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mfull_posts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubreddit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m#if full_posts is None:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0;31m#raise ValueError(\"Response is empty or none.\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'get_request' is not defined"]}]},{"cell_type":"code","metadata":{"id":"tvbLzAGHuHoT"},"source":["\"\"\"\n","OUTPUT TO CSVVVVVVV\n","\n","using RDD and DF\n","\"\"\"\n","# convert unix timestamp to date e.g.: '2021-04-04'\n","def convert_to_date(timestamp):\n","  return str(datetime.fromtimestamp(int(timestamp)).date())\n","\n","posts_rdd = spark.sparkContext.parallelize(posts)\n","posts_rdd = posts_rdd.map(lambda post: Row(id=post['id'], ticker=post['ticker'], growth=post['growth'], title=post['title'], flair=str(post['flair']), score=post['score'], upvote_ratio=post['upvote_ratio'], author=str(post['author']), num_comments=post['num_comments'], text=post['text'].lower(), created=convert_to_date(post['created_utc']), url=post['url']))\n","# eliminate duplicates\n","posts_rdd = posts_rdd.distinct()\n","# serialize rdd, maybe better as pandas?\n","#posts_rdd.saveAsPickleFile(\"pickled_WSBposts_rdd-test\")\n","\n","# convert to DF\n","posts_df = spark.createDataFrame(posts_rdd)\n","print(posts_df.count())\n","panda_posts = posts_df.toPandas()\n","\n","# write to csv\n","posts_df.coalesce(1).write.csv('fullflairs-60daysredditposts.csv', header=True)\n","panda_posts"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IJIjyjJc6d0M"},"source":["'''\n","Read from pickle file.\n","'''\n","# read csv\n","#p = spark.read.csv(\"90daysredditposts.csv\", header=True)\n","#removednumbers_rdd = p.rdd.map(lambda post: Row(id=post['id'], ticker=post['ticker'], growth=post['growth'], title=post['title'], flair=str(post['flair']), score=post['score'], upvote_ratio=post['upvote_ratio'], author=str(post['author']), num_comments=post['num_comments'], text=post['text'].translate({ord(k): None for k in string.digits}), created=post['created'], url=post['url']))\n","#df = removednumbers_rdd.toDF()\n","#df.coalesce(1).write.csv('removednumbers-60daysredditposts.csv', header=True)\n","\n","#df.show()\n","# read pickle (pandas)\n","#pandas_posts = pd.read_pickle(\"pickled_WSB_posts\")\n","'''\n","# read pickle (spark)\n","spark_posts = spark.sparkContext.pickleFile(\"pickled_WSBposts\").collect()\n","posts_df_pickled = spark.createDataFrame(spark_posts)\n","posts_df_pickled.show()\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U85DTfdbwgzS"},"source":["for i in posts:\n","  print(i[\"score\"])"],"execution_count":null,"outputs":[]}]}