{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjectWallStreetBets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSmCrU8CYLkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "607e3855-12b3-43c5-d995-90dcdc2f95f6"
      },
      "source": [
        "!pip install pyspark\r\n",
        "!pip install praw"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n",
            "Collecting praw\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/a8/a2e2d0750ee17c7e3d81e4695a0338ad0b3f231853b8c3fa339ff2d25c7c/praw-7.2.0-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 7.7MB/s \n",
            "\u001b[?25hCollecting prawcore<3,>=2\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/df/4a9106bea0d26689c4b309da20c926a01440ddaf60c09a5ae22684ebd35f/prawcore-2.0.0-py3-none-any.whl\n",
            "Collecting update-checker>=0.18\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/ba/8dd7fa5f0b1c6a8ac62f8f57f7e794160c1f86f31c6d0fb00f582372a3e4/update_checker-0.18.0-py3-none-any.whl\n",
            "Collecting websocket-client>=0.54.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/33/80e0d4f60e84a1ddd9a03f340be1065a2a363c47ce65c4bd3bae65ce9631/websocket_client-0.58.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from prawcore<3,>=2->praw) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from websocket-client>=0.54.0->praw) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2->praw) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2->praw) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2->praw) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2->praw) (1.24.3)\n",
            "Installing collected packages: prawcore, update-checker, websocket-client, praw\n",
            "Successfully installed praw-7.2.0 prawcore-2.0.0 update-checker-0.18.0 websocket-client-0.58.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV_t_JDlZHAg"
      },
      "source": [
        "from pyspark.rdd import RDD\r\n",
        "from pyspark.sql import Row\r\n",
        "from pyspark.sql import DataFrame\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "from pyspark.sql.functions import lit\r\n",
        "from pyspark.sql.functions import desc\r\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\r\n",
        "from pyspark.ml.recommendation import ALS\r\n",
        "from pyspark import SparkContext as sc\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "from pyspark.sql import functions as F\r\n",
        "# tools\r\n",
        "import math\r\n",
        "import json\r\n",
        "import requests\r\n",
        "import itertools\r\n",
        "import numpy as np\r\n",
        "import time\r\n",
        "from datetime import datetime, timedelta\r\n",
        "\r\n",
        "def init_spark():\r\n",
        "    spark = SparkSession \\\r\n",
        "        .builder \\\r\n",
        "        .appName(\"Python Spark SQL basic example\") \\\r\n",
        "        .config(\"spark.some.config.option\", \"some-value\") \\\r\n",
        "        .getOrCreate()\r\n",
        "    return spark\r\n",
        "spark = init_spark()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTAG1HhPIZLn"
      },
      "source": [
        "\"\"\"\r\n",
        "Function to make an HTTP request to the Pushshift API.\r\n",
        "- max_retry: Nb of times the request is re-tried if failure occurs.\r\n",
        "- returns: Python object with the content of the request. (index 'data' property)\r\n",
        "\"\"\"\r\n",
        "def get_request(uri, max_retry = 5):\r\n",
        "  def get(uri):\r\n",
        "    response = requests.get(uri)\r\n",
        "    assert response.status_code == 200\r\n",
        "    return json.loads(response.content)\r\n",
        "  # Retry if request call failed\r\n",
        "  retry = 1\r\n",
        "  while retry < max_retry:\r\n",
        "    try:\r\n",
        "      response = get(uri)\r\n",
        "      return response\r\n",
        "    except:\r\n",
        "      print(f\"[{retry}] Request failed, re-trying...\")\r\n",
        "      # wait 1 second before retry\r\n",
        "      time.sleep(1)\r\n",
        "      retry += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgUPYZ8kni0H",
        "outputId": "5e4e6e4f-51e0-4368-a630-9fe1bc1587b5"
      },
      "source": [
        "# Testing get_request() with test uri. Should return a non-empty Python object.\r\n",
        "obj = get_request(\"https://httpbin.org/get\")\r\n",
        "print(obj['url'])\r\n",
        "# Returning posts from wallstreetbets. The posts are in the \"data\" property of the response.\r\n",
        "# Use this to check format: https://jsonformatter.curiousconcept.com/#\r\n",
        "# obj2 = get_request('https://api.pushshift.io/reddit/search/submission?subreddit=wallstreetbets')\r\n",
        "# print(obj2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://httpbin.org/get\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQkcQb6TnlR_"
      },
      "source": [
        "\"\"\"\r\n",
        "Gets the all the posts from a given subreddit in the specific time range.\r\n",
        "- subreddit: name of subreddit\r\n",
        "- begin: timestamp (in unix) of start date\r\n",
        "- end: timestamp (in unix) of end date\r\n",
        "- returns: list of all the posts in the time interval. the posts are objects with properties \"id\", \"title\" and \"creation_utc\".\r\n",
        "\"\"\"\r\n",
        "def get_posts(subreddit, begin, end):\r\n",
        "  # Max size of Pushshift API retrieve is 500 posts.\r\n",
        "  SIZE = 100\r\n",
        "  PUSHSHIFT_URI = r'https://api.pushshift.io/reddit/search/submission?subreddit={}&after={}&before={}&size={}'\r\n",
        "  nb_requests_made = 1\r\n",
        "\r\n",
        "  # Get the ids and creation time of the posts only. Can use later to get the actual posts with PRAW with these ids.\r\n",
        "  # Alternatively, we could also directly use get_request() instead of this function, and get all the posts with their content.\r\n",
        "  def filter_ids_time(uri, begin, end):\r\n",
        "    full_posts = get_request(uri.format(subreddit, begin, end, SIZE))\r\n",
        "    # Test prints\r\n",
        "    #if nb_requests_made != 1:\r\n",
        "    #  print(f\"Retrieved full_posts {nb_requests_made} times\", len(full_posts['data']))\r\n",
        "    if full_posts is None:\r\n",
        "      raise ValueError(\"Response is empty or none.\")\r\n",
        "\r\n",
        "    filtered = map(lambda post: {\r\n",
        "        'id': post['id'],\r\n",
        "        'title': post['title'],\r\n",
        "        'created_utc': post['created_utc']\r\n",
        "    }, full_posts['data'])\r\n",
        "    return list(filtered)\r\n",
        "\r\n",
        "  posts = filter_ids_time(PUSHSHIFT_URI, begin, end)\r\n",
        "  posts_amount = len(posts)\r\n",
        "  # If reached limit of 500 posts retrieved, make request again until 'end' time.\r\n",
        "  while posts_amount == SIZE:\r\n",
        "    # Timestamp of the last post we previously retrieved\r\n",
        "    new_begin = posts[-1]['created_utc'] - 10\r\n",
        "    more_posts = filter_ids_time(PUSHSHIFT_URI, new_begin, end)\r\n",
        "    posts_amount = len(more_posts)\r\n",
        "    posts.extend(more_posts)\r\n",
        "    nb_requests_made += 1\r\n",
        "  \r\n",
        "  return posts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfcmDOgEv0qC",
        "outputId": "1fb47e5b-3718-4d1c-acb4-60308871aabf"
      },
      "source": [
        "\"\"\"\r\n",
        "Testing get_posts() function.\r\n",
        "- Timestamp converter: https://www.unixtimestamp.com/index.php?ref=theredish.com%2Fweb\r\n",
        "- Able to retrieve up till latest posts from 6 hours ago.\r\n",
        "- To print till \"now\": math.ceil(datetime.utcnow().timestamp())\r\n",
        "\"\"\"\r\n",
        "# Posts from March 13th\r\n",
        "#posts = get_posts('wallstreetbets', 1615687200, math.ceil(datetime.utcnow().timestamp()))\r\n",
        "# All posts from nb_days_from_today\r\n",
        "nb_days_from_today = 5\r\n",
        "begin = math.ceil((datetime.utcnow() - timedelta(days=nb_days_from_today)).timestamp())\r\n",
        "end = math.ceil(datetime.utcnow().timestamp())\r\n",
        "print(\"Timestamps: \", begin, end)\r\n",
        "posts = get_posts('wallstreetbets', begin, end)\r\n",
        "unique_posts = np.unique([post['id'] for post in posts])\r\n",
        "# Use np.unique to get rid of duplicates and filter posts only by id (only need id for praw).\r\n",
        "print(\"Size: \", len(posts))\r\n",
        "print(\"Size of uniques: \", len(unique_posts))\r\n",
        "print(\"Example posts: \", unique_posts[:5])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Timestamps:  1615342779 1615774779\n",
            "Size:  30737\n",
            "Size of uniques:  29970\n",
            "Example posts:  ['m1mx0q' 'm1mx54' 'm1mx6b' 'm1mx8k' 'm1mxo2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ1BTHOcEHCp"
      },
      "source": [
        "import praw\r\n",
        "import os\r\n",
        "\"\"\"\r\n",
        "Connect to Reddit API using environment variables. (values from reddit app)\r\n",
        "- returns: reddit instance\r\n",
        "\"\"\"\r\n",
        "def connect_reddit():\r\n",
        "  reddit = praw.Reddit(\r\n",
        "    username = \"fryingpannnnnn\", #os.environ['REDDIT_NAME'],\r\n",
        "    password = \"wsbpan123\", #os.environ['REDDIT_PASS'],\r\n",
        "    client_secret = \"GWFFdjptuoOsDPjpxERQsBY-xV7GfQ\", #os.environ['REDDIT_SECRET'],\r\n",
        "    client_id = \"VWDfl0X3JFVwWQ\", #os.environ['REDDIT_CLIENTWSB'],\r\n",
        "    user_agent = \"wsbscrape\"\r\n",
        "  )\r\n",
        "  return reddit"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0CTy1LKcTaH",
        "outputId": "14b5fade-39a8-4683-bede-24ea5acc1ecc"
      },
      "source": [
        "# Testing connect_reddit() function\r\n",
        "# Should print \"<praw.reddit.Reddit object at ...>\"\r\n",
        "reddit = connect_reddit()\r\n",
        "print(reddit)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<praw.reddit.Reddit object at 0x7fe1a9c60110>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTlndzbWc1FG"
      },
      "source": [
        "\"\"\"\r\n",
        "Function to retrieve all Reddit posts of given ids.\r\n",
        "- unique_posts: the id of the posts you want to retrieve.\r\n",
        "- returns: list of reddit submission instances (reddit posts) of the input ids.\r\n",
        "\"\"\"\r\n",
        "def get_reddit_posts(unique_posts):\r\n",
        "  reddit = connect_reddit()\r\n",
        "  PAUSE_BEFORE_NEXT_CALL = 0.3\r\n",
        "\r\n",
        "  reddit_posts = []\r\n",
        "\r\n",
        "  for post_id in unique_posts:\r\n",
        "    reddit_posts.append(reddit.submission(id=post_id))\r\n",
        "    time.sleep(PAUSE_BEFORE_NEXT_CALL)\r\n",
        "\r\n",
        "  return reddit_posts"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To3f1xXhqxvb",
        "outputId": "d77e444f-cd06-4f5a-ee2e-68acc80d0489"
      },
      "source": [
        "# Testing get_reddit_posts(): retrieving 1000 posts.\r\n",
        "thousand_posts = unique_posts[:1000]\r\n",
        "reddit_posts = get_reddit_posts(thousand_posts)\r\n",
        "print(\"Size of posts: \", len(reddit_posts))\r\n",
        "print(\"First 5 posts: \", reddit_posts[:5])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of posts:  1000\n",
            "First 5 posts:  [Submission(id='m1mx0q'), Submission(id='m1mx54'), Submission(id='m1mx6b'), Submission(id='m1mx8k'), Submission(id='m1mxo2')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or84I9x0x5q2",
        "outputId": "3c04af3f-528a-4e04-e697-a5324985b6bd"
      },
      "source": [
        "reddit_posts[0].score"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U3fYkj_x9w0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}